{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50  # Example model\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def save_gradients(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.features = output\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.save_gradients(grad_out[0])\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.target_layer:\n",
    "                module.register_forward_hook(forward_hook)\n",
    "                module.register_backward_hook(backward_hook)\n",
    "\n",
    "    def __call__(self, x, index=None):\n",
    "        output = self.model(x)\n",
    "        if index is None:\n",
    "            index = output.argmax(dim=1)\n",
    "        \n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[range(one_hot.shape[0]), index] = 1\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            weights = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "            grad_cam = F.relu((weights * self.features).sum(dim=1)).squeeze(0)\n",
    "        \n",
    "        return grad_cam\n",
    "\n",
    "# Example usage\n",
    "model = resnet50(pretrained=True)\n",
    "grad_cam = GradCAM(model, target_layer='layer4')  # Specify the target layer\n",
    "# Prepare your input image\n",
    "# input_image = ...\n",
    "# grad_cam_map = grad_cam(input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import inception_v3, xception  # Placeholder for actual EfficientNet models\n",
    "\n",
    "# Assuming EfficientNet B1, B2, B3 are similar to these placeholder models for demonstration\n",
    "models = {\n",
    "    'B1': EfficientNet.from_pretrained('efficientnet-b1'),\n",
    "    'B2': EfficientNet.from_pretrained('efficientnet-b2'),\n",
    "    'B3': EfficientNet.from_pretrained('efficientnet-b3'),\n",
    "}\n",
    "\n",
    "# Modify models for feature extraction\n",
    "for model in models.values():\n",
    "    model._fc = nn.Identity()\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = ImageFolder(root='/path/to/train/data', transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Ensemble Model\n",
    "class EnsembleEfficientNet(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(EnsembleEfficientNet, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        self.classifier = nn.Linear(sum([model._fc.in_features for model in models]), 2)  # Assuming binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = torch.cat([model(x) for model in self.models], dim=1)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "# Initialize ensemble model\n",
    "ensemble_model = EnsembleEfficientNet(models=[models['B1'], models['B2'], models['B3']])\n",
    "\n",
    "# Training specifics\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    ensemble_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ensemble_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "# Note: Grad-CAM implementation and specific fine-tuning strategies as described in the document would require additional code.\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50  # Example model\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def save_gradients(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.features = output\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.save_gradients(grad_out[0])\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.target_layer:\n",
    "                module.register_forward_hook(forward_hook)\n",
    "                module.register_backward_hook(backward_hook)\n",
    "\n",
    "    def __call__(self, x, index=None):\n",
    "        output = self.model(x)\n",
    "        if index is None:\n",
    "            index = output.argmax(dim=1)\n",
    "        \n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[range(one_hot.shape[0]), index] = 1\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            weights = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "            grad_cam = F.relu((weights * self.features).sum(dim=1)).squeeze(0)\n",
    "        \n",
    "        return grad_cam\n",
    "\n",
    "# Example usage\n",
    "model = resnet50(pretrained=True)\n",
    "grad_cam = GradCAM(model, target_layer='layer4')  # Specify the target layer\n",
    "# Prepare your input image\n",
    "# input_image = ...\n",
    "# grad_cam_map = grad_cam(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EnsembleGradCAM:\n",
    "    def __init__(self, models, target_layers):\n",
    "        self.models = models\n",
    "        self.target_layers = target_layers\n",
    "        self.features = []\n",
    "        self.gradients = []\n",
    "        self.register_hooks()\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for model, target_layer in zip(self.models, self.target_layers):\n",
    "            model.eval()\n",
    "\n",
    "            def forward_hook(module, input, output):\n",
    "                self.features.append(output)\n",
    "\n",
    "            def backward_hook(module, grad_in, grad_out):\n",
    "                self.gradients.append(grad_out[0])\n",
    "\n",
    "            layer = dict([*model.named_modules()])[target_layer]\n",
    "            layer.register_forward_hook(forward_hook)\n",
    "            layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Forward pass\n",
    "        for model in self.models:\n",
    "            _ = model(x)\n",
    "        \n",
    "        # Combine feature maps\n",
    "        combined_features = torch.mean(torch.stack(self.features), dim=0)\n",
    "        # Generate a pseudo output for backprop\n",
    "        score = combined_features.mean(dim=[2, 3], keepdim=True).sum()\n",
    "\n",
    "        # Backward pass\n",
    "        self.models[0].zero_grad()  # Assuming all models share parameters\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        # Combine gradients\n",
    "        combined_gradients = torch.mean(torch.stack(self.gradients), dim=0)\n",
    "        \n",
    "        # Apply ReLU to the combined feature maps\n",
    "        weights = F.relu(combined_gradients)\n",
    "        grad_cam = torch.mul(combined_features, weights).sum(dim=1).clamp(min=0)\n",
    "\n",
    "        return grad_cam\n",
    "\n",
    "# Initialize models\n",
    "models = [EfficientNet.from_pretrained(f'efficientnet-b{i}') for i in range(1, 4)]\n",
    "target_layers = ['_blocks.22', '_blocks.22', '_blocks.22']  # Example target layers\n",
    "\n",
    "# Initialize EnsembleGradCAM\n",
    "ensemble_grad_cam = EnsembleGradCAM(models, target_layers)\n",
    "\n",
    "# Prepare your input image and apply EnsembleGradCAM\n",
    "# input_image = ...\n",
    "# grad_cam_map = ensemble_grad_cam(input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root='/path/to/train/data', transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "class EnsembleEfficientNet(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(EnsembleEfficientNet, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        # Assuming binary classification for simplicity\n",
    "        self.classifier = nn.Linear(sum([model._fc.in_features for model in models]), 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = torch.cat([model(x) for model in self.models], dim=1)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "models = {\n",
    "    'B1': EfficientNet.from_pretrained('efficientnet-b1'),\n",
    "    'B2': EfficientNet.from_pretrained('efficientnet-b2'),\n",
    "    'B3': EfficientNet.from_pretrained('efficientnet-b3'),\n",
    "}\n",
    "\n",
    "# Modify models for feature extraction\n",
    "for model in models.values():\n",
    "    model._fc = nn.Identity()\n",
    "\n",
    "ensemble_model = EnsembleEfficientNet(models=[models['B1'], models['B2'], models['B3']])\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):  # Adjust epochs as needed\n",
    "    ensemble_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ensemble_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "    \n",
    "class EnsembleGradCAM:\n",
    "    def __init__(self, models, target_layers):\n",
    "        \"\"\"\n",
    "        Initializes the EnsembleGradCAM.\n",
    "        \n",
    "        :param models: A list of models to be included in the ensemble.\n",
    "        :param target_layers: A list of target layer names for each model where gradients should be captured.\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "        self.features = []\n",
    "\n",
    "        self.register_hooks()\n",
    "\n",
    "    def register_hooks(self):\n",
    "        \"\"\"\n",
    "        Registers forward and backward hooks on the target layers of each model.\n",
    "        \"\"\"\n",
    "        for model, target_layer in zip(self.models, self.target_layers):\n",
    "            model.eval()  # Set model to evaluation mode to disable dropout, etc.\n",
    "            \n",
    "            def forward_hook(module, input, output):\n",
    "                self.features.append(output)\n",
    "                \n",
    "            def backward_hook(module, input, output):\n",
    "                self.gradients.append(output[0])\n",
    "                \n",
    "            # Retrieve the target layer\n",
    "            layer = dict([*model.named_modules()])[target_layer]\n",
    "            # Register hooks\n",
    "            layer.register_forward_hook(forward_hook)\n",
    "            layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass and computes the GradCAM for the ensemble.\n",
    "        \n",
    "        :param x: Input tensor.\n",
    "        :return: A tensor representing the GradCAM output.\n",
    "        \"\"\"\n",
    "        self.features = []\n",
    "        self.gradients = []\n",
    "        \n",
    "        # Forward pass through each model\n",
    "        for model in self.models:\n",
    "            _ = model(x)\n",
    "        \n",
    "        # Aggregate and process the features and gradients here as necessary\n",
    "        # This can involve averaging or another method of combining the information\n",
    "        # from different models\n",
    "        \n",
    "        # Example: Averaging the features and gradients\n",
    "        # Note: This is a simplification. You might need a more sophisticated method to combine these.\n",
    "        avg_features = torch.mean(torch.stack(self.features), dim=0)\n",
    "        avg_gradients = torch.mean(torch.stack(self.gradients), dim=0)\n",
    "\n",
    "        # Use the processed features and gradients to compute GradCAM\n",
    "        # This is a simplified version; adapt as necessary for your use case.\n",
    "        gcam = self.compute_gradcam(avg_features, avg_gradients)\n",
    "        \n",
    "        return gcam\n",
    "\n",
    "    def compute_gradcam(self, features, gradients):\n",
    "        \"\"\"\n",
    "        Computes the GradCAM based on features and gradients.\n",
    "        \n",
    "        :param features: Aggregated features from the forward hook.\n",
    "        :param gradients: Aggregated gradients from the backward hook.\n",
    "        :return: GradCAM output.\n",
    "        \"\"\"\n",
    "        # Weight the channels by corresponding gradients\n",
    "        weights = torch.mean(gradients, dim=[2, 3], keepdim=True)\n",
    "        gcam = torch.mul(features, weights).sum(dim=1, keepdim=True)\n",
    "        gcam = F.relu(gcam)  # Apply ReLU to the GradCAM\n",
    "        \n",
    "        # Normalize the GradCAM\n",
    "        gcam = gcam - gcam.min()\n",
    "        gcam = gcam / gcam.max()\n",
    "        \n",
    "        return gcam\n",
    "    \n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EnsembleGradCAM:\n",
    "    def __init__(self, models, target_layers):\n",
    "        self.models = models\n",
    "        self.target_layers = target_layers\n",
    "        self.features = []\n",
    "        self.gradients = []\n",
    "        self.register_hooks()\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for model, target_layer in zip(self.models, self.target_layers):\n",
    "            model.eval()\n",
    "\n",
    "            def forward_hook(module, input, output):\n",
    "                self.features.append(output)\n",
    "\n",
    "            def backward_hook(module, grad_in, grad_out):\n",
    "                self.gradients.append(grad_out[0])\n",
    "\n",
    "            layer = dict([*model.named_modules()])[target_layer]\n",
    "            layer.register_forward_hook(forward_hook)\n",
    "            layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Forward pass\n",
    "        for model in self.models:\n",
    "            _ = model(x)\n",
    "        \n",
    "        # Combine feature maps\n",
    "        combined_features = torch.mean(torch.stack(self.features), dim=0)\n",
    "        # Generate a pseudo output for backprop\n",
    "        score = combined_features.mean(dim=[2, 3], keepdim=True).sum()\n",
    "\n",
    "        # Backward pass\n",
    "        self.models[0].zero_grad()  # Assuming all models share parameters\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        # Combine gradients\n",
    "        combined_gradients = torch.mean(torch.stack(self.gradients), dim=0)\n",
    "        \n",
    "        # Apply ReLU to the combined feature maps\n",
    "        weights = F.relu(combined_gradients)\n",
    "        grad_cam = torch.mul(combined_features, weights).sum(dim=1).clamp(min=0)\n",
    "\n",
    "        return grad_cam\n",
    "\n",
    "# Initialize models\n",
    "models = [EfficientNet.from_pretrained(f'efficientnet-b{i}') for i in range(1, 4)]\n",
    "target_layers = ['_blocks.22', '_blocks.22', '_blocks.22']  # Example target layers\n",
    "\n",
    "# Initialize EnsembleGradCAM\n",
    "ensemble_grad_cam = EnsembleGradCAM(models, target_layers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastaiv2",
   "language": "python",
   "name": "fastaiv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
