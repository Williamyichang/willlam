{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/william/HDD_1TB/AI_competition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "print(os.getcwd())\n",
    "classes_file = open('project_classes.txt','w')\n",
    "paths = glob.glob('./train_dataset/*')\n",
    "for path in paths:\n",
    "    classes = os.path.basename(path)\n",
    "    classes_file.write(classes+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/william/HDD_1TB/AI_competition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "os.getcwd()\n",
    "print(os.getcwd())\n",
    "\n",
    "paths = glob.glob('./train_dataset/*')\n",
    "#print(paths)\n",
    "list_file_xml = open('./train_dataset_path/trainset_bounding_box.txt', 'w')\n",
    "list_file_filename = open('./train_dataset_path/trainset_filename.txt', 'w')\n",
    "\n",
    "def get_filename(file):\n",
    "    \n",
    "    tree=ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    # to get the filename for each image\n",
    "    for image in root.iter('annotation'):\n",
    "        image_path = image.find('filename').text\n",
    "        list_file_filename.write(str(image_path)+'\\n')\n",
    "    #list_file_xml.write('\\n')       \n",
    "\n",
    "    \n",
    "def get_convert_annotation(file):\n",
    "    tree=ET.parse(file)\n",
    "    root = tree.getroot()\n",
    " \n",
    "    # to get bounding box data for each image\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult)==1:\n",
    "        #if cls not in classes:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
    "        #list_file.write(\" \" + \",\" + str(b) + ',' + str(cls_id)+'\\n')\n",
    "        #list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id)+'\\n')\n",
    "        list_file_xml.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))     \n",
    "    list_file_xml.write('\\n')\n",
    "    #list_file_filename.write('\\n')\n",
    "\n",
    "for path in paths:\n",
    "    classes = os.path.basename(path)\n",
    "    in_file = '/data_path/%s/'%(classes)\n",
    "    for path_1 in glob.glob(in_file + \"*\"):\n",
    "        paths = os.path.basename(path_1)\n",
    "        in_file_1 = in_file + paths\n",
    "        for path_2 in glob.glob(in_file_1+\"/*\"):\n",
    "            paths_1 = os.path.basename(path_2)\n",
    "            in_file_2 = in_file_1 +'/'+ paths_1\n",
    "            for anno in glob.glob(in_file_2 + '/*.xml'):\n",
    "#                 print(anno)\n",
    "                in_file_3 = open(anno)\n",
    "                get_convert_annotation(anno)\n",
    "                get_filename(anno)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine image file and bounding box  \n",
    "\n",
    "with open(\"./train_dataset_path/trainset_filename.txt\") as tr:\n",
    "    with open('./train_dataset_path/trainset_bounding_box.txt') as im:\n",
    "        with open(\"./train_dataset_path/trainset_combine.txt\",\"w\") as ts:\n",
    "            #Read first file\n",
    "            xlines = tr.readlines()\n",
    "            #Read second file\n",
    "            ylines = im.readlines()\n",
    "            #Combine content of both lists  and Write to third file\n",
    "            for line1, line2 in zip(xlines, ylines):\n",
    "                 ts.write(\"{}{}\\n\".format(line1.rstrip(), line2.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "list_file_image = open('./train_dataset_path/image_path_1.txt','w')\n",
    "\n",
    "paths = glob.glob('./train_dataset/*')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def image_path(path):\n",
    "    list_file_image.write(path+'\\n')\n",
    "    \n",
    "for path in paths:\n",
    "    classes = os.path.basename(path)\n",
    "    in_file = '/data_path/%s/'%(classes)\n",
    "    for path_1 in glob.glob(in_file + \"*\"):\n",
    "        paths = os.path.basename(path_1)\n",
    "        in_file_1 = in_file + paths\n",
    "        for path_2 in glob.glob(in_file_1+\"/*\"):\n",
    "            paths_1 = os.path.basename(path_2)\n",
    "            in_file_2 = in_file_1 +'/'+ paths_1\n",
    "            #print(in_file_2)\n",
    "            for anno in glob.glob(in_file_2 + '/*.xml'):\n",
    "               \n",
    "                      \n",
    "                # to get the foilder of last one, which image in\n",
    "                anno_1 = os.path.basename(anno)\n",
    "                anno_1 = os.path.split(anno_1)[1]\n",
    "                anno_1 = str(anno_1)\n",
    "                anno_1 = anno_1.split('.')[0]\n",
    "                #anno_1 = in_file_2 +'/'+ anno_1 +'/'+ '.png'\n",
    "                anno_1 = in_file_2 +'/'\n",
    "                #print(anno_1)\n",
    "                #list_file_image.write(str(anno_1)+'\\n')\n",
    "                image_path(anno_1)\n",
    "                #print(anno_1)\n",
    "end_time = time.time()\n",
    "\n",
    "time_caculate = end_time-start_time\n",
    "\n",
    "print('{:.2f}'.format(time_caculate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine image file and bounding box  \n",
    "\n",
    "with open(\"./train_dataset_path/image_path_1.txt\") as ip:\n",
    "    with open('./train_dataset_path/trainset_combine.txt') as tc :\n",
    "        with open(\"./train_dataset_path/trainset_final.txt\",\"w\") as tl:\n",
    "            #Read first file\n",
    "            xlines = ip.readlines()\n",
    "            #Read second file\n",
    "            ylines = tc.readlines()\n",
    "            #Combine content of both lists  and Write to third file\n",
    "            for line1, line2 in zip(xlines, ylines):\n",
    "                 tl.write(\"{}{}\\n\".format(line1.rstrip(), line2.rstrip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#print(os.getcwd())\n",
    "paths = glob.glob('/data_path/*.png')\n",
    "list_file_1 = open('test_file_path.txt','w')\n",
    "list_filename = open('test_1.txt','w')\n",
    "#print(paths)\n",
    "for path in paths:\n",
    "    file_path = os.path.dirname(path)\n",
    "    file_name = os.path.basename(path)\n",
    "    #file_name = os.path.split('.')\n",
    "    list_file_1.write(str(file_path)+'\\n')\n",
    "    list_filename.write(str(file_name)+'\\n')\n",
    "# list_file_1.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the path,image file and bounding box  \n",
    "\n",
    "with open(\"test_1.txt\") as tr:\n",
    "    with open('test_file_path.txt') as im:\n",
    "        with open(\"testset.txt\",\"w\") as ts:\n",
    "            #Read first file\n",
    "            xlines = tr.readlines()\n",
    "            #Read second file\n",
    "            ylines = im.readlines()\n",
    "            #Combine content of both lists  and Write to third file\n",
    "            for line1, line2 in zip(ylines, xlines):\n",
    "                 ts.write(\"{}/{}\\n\".format(line1.rstrip(), line2.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
